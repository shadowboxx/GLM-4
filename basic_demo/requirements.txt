<<<<<<< HEAD
# use vllm
vllm>=0.5.0

torch>=2.3.0
torchvision>=0.18.0
transformers==4.40.0
huggingface-hub>=0.23.1
sentencepiece>=0.2.0
pydantic>=2.7.1
timm>=0.9.16
tiktoken>=0.7.0
accelerate>=0.30.1
sentence_transformers>=2.7.0

# web demo
gradio>=4.33.0

# openai demo
openai>=1.34.0
einops>=0.7.0
sse-starlette>=2.1.0

# INT4
bitsandbytes>=0.43.1

# PEFT model, not need if you don't use PEFT finetune model.
peft>=0.11.0
=======
torch>=2.3.0
torchvision>=0.18.0
transformers==4.42.4
huggingface-hub>=0.23.1
sentencepiece>=0.2.0
pydantic>=2.8.2
timm>=1.0.7
tiktoken>=0.7.0
accelerate>=0.32.1
sentence_transformers>=3.0.1
gradio>=4.38.1 # web demo
openai>=1.35.0 # openai demo
einops>=0.8.0
sse-starlette>=2.1.2
bitsandbytes>=0.43.1 # INT4 Loading

# vllm>=0.5.2
# flash-attn>=2.5.9 # using with flash-attention 2
# PEFT model, not need if you don't use PEFT finetune model.
# peft>=0.11.1
>>>>>>> 0b80c79b8c04ccbf78490211fb848e4a1b8c716e
